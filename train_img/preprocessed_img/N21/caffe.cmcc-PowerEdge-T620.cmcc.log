Log file created at: 2016/12/16 13:23:40
Running on machine: cmcc-PowerEdge-T620
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1216 13:23:40.444285 34688 caffe.cpp:217] Using GPUs 0
I1216 13:23:40.453431 34688 caffe.cpp:222] GPU 0: TITAN X (Pascal)
I1216 13:23:41.011600 34688 solver.cpp:60] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 1e-05
display: 1000
max_iter: 100000
lr_policy: "step"
gamma: 0.8
momentum: 0.9
weight_decay: 0.0004
stepsize: 10000
snapshot: 5000
snapshot_prefix: "../model/"
solver_mode: GPU
device_id: 0
net: "./train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I1216 13:23:41.011981 34688 solver.cpp:103] Creating training net from net file: ./train_val.prototxt
I1216 13:23:41.013155 34688 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1216 13:23:41.013223 34688 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1216 13:23:41.013416 34688 net.cpp:58] Initializing net from parameters: 
name: "face_alignment_full_net"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "../train_hdf5.txt"
    batch_size: 64
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 40
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 60
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1216 13:23:41.013615 34688 layer_factory.hpp:77] Creating layer data
I1216 13:23:41.013654 34688 net.cpp:100] Creating Layer data
I1216 13:23:41.013671 34688 net.cpp:408] data -> data
I1216 13:23:41.013711 34688 net.cpp:408] data -> label
I1216 13:23:41.013736 34688 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: ../train_hdf5.txt
I1216 13:23:41.013799 34688 hdf5_data_layer.cpp:93] Number of HDF5 files: 2
I1216 13:23:41.015362 34688 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1216 13:23:41.086835 34688 net.cpp:150] Setting up data
I1216 13:23:41.086928 34688 net.cpp:157] Top shape: 64 3 15 15 (43200)
I1216 13:23:41.086953 34688 net.cpp:157] Top shape: 64 2 1 1 (128)
I1216 13:23:41.086969 34688 net.cpp:165] Memory required for data: 173312
I1216 13:23:41.086995 34688 layer_factory.hpp:77] Creating layer conv1
I1216 13:23:41.087060 34688 net.cpp:100] Creating Layer conv1
I1216 13:23:41.087086 34688 net.cpp:434] conv1 <- data
I1216 13:23:41.087122 34688 net.cpp:408] conv1 -> conv1
I1216 13:23:41.487043 34688 net.cpp:150] Setting up conv1
I1216 13:23:41.487133 34688 net.cpp:157] Top shape: 64 20 12 12 (184320)
I1216 13:23:41.487154 34688 net.cpp:165] Memory required for data: 910592
I1216 13:23:41.487241 34688 layer_factory.hpp:77] Creating layer pool1
I1216 13:23:41.487282 34688 net.cpp:100] Creating Layer pool1
I1216 13:23:41.487318 34688 net.cpp:434] pool1 <- conv1
I1216 13:23:41.487341 34688 net.cpp:408] pool1 -> pool1
I1216 13:23:41.487457 34688 net.cpp:150] Setting up pool1
I1216 13:23:41.487488 34688 net.cpp:157] Top shape: 64 20 11 11 (154880)
I1216 13:23:41.487504 34688 net.cpp:165] Memory required for data: 1530112
I1216 13:23:41.487519 34688 layer_factory.hpp:77] Creating layer relu1
I1216 13:23:41.487538 34688 net.cpp:100] Creating Layer relu1
I1216 13:23:41.487553 34688 net.cpp:434] relu1 <- pool1
I1216 13:23:41.487572 34688 net.cpp:395] relu1 -> pool1 (in-place)
I1216 13:23:41.487854 34688 net.cpp:150] Setting up relu1
I1216 13:23:41.487886 34688 net.cpp:157] Top shape: 64 20 11 11 (154880)
I1216 13:23:41.487903 34688 net.cpp:165] Memory required for data: 2149632
I1216 13:23:41.487920 34688 layer_factory.hpp:77] Creating layer conv2
I1216 13:23:41.487953 34688 net.cpp:100] Creating Layer conv2
I1216 13:23:41.487970 34688 net.cpp:434] conv2 <- pool1
I1216 13:23:41.487990 34688 net.cpp:408] conv2 -> conv2
I1216 13:23:41.490185 34688 net.cpp:150] Setting up conv2
I1216 13:23:41.490226 34688 net.cpp:157] Top shape: 64 40 9 9 (207360)
I1216 13:23:41.490243 34688 net.cpp:165] Memory required for data: 2979072
I1216 13:23:41.490268 34688 layer_factory.hpp:77] Creating layer pool2
I1216 13:23:41.490289 34688 net.cpp:100] Creating Layer pool2
I1216 13:23:41.490306 34688 net.cpp:434] pool2 <- conv2
I1216 13:23:41.490325 34688 net.cpp:408] pool2 -> pool2
I1216 13:23:41.490406 34688 net.cpp:150] Setting up pool2
I1216 13:23:41.490433 34688 net.cpp:157] Top shape: 64 40 8 8 (163840)
I1216 13:23:41.490450 34688 net.cpp:165] Memory required for data: 3634432
I1216 13:23:41.490468 34688 layer_factory.hpp:77] Creating layer relu2
I1216 13:23:41.490486 34688 net.cpp:100] Creating Layer relu2
I1216 13:23:41.490501 34688 net.cpp:434] relu2 <- pool2
I1216 13:23:41.490520 34688 net.cpp:395] relu2 -> pool2 (in-place)
I1216 13:23:41.490813 34688 net.cpp:150] Setting up relu2
I1216 13:23:41.490844 34688 net.cpp:157] Top shape: 64 40 8 8 (163840)
I1216 13:23:41.490860 34688 net.cpp:165] Memory required for data: 4289792
I1216 13:23:41.490875 34688 layer_factory.hpp:77] Creating layer ip1
I1216 13:23:41.490902 34688 net.cpp:100] Creating Layer ip1
I1216 13:23:41.490919 34688 net.cpp:434] ip1 <- pool2
I1216 13:23:41.490942 34688 net.cpp:408] ip1 -> ip1
I1216 13:23:41.500285 34688 net.cpp:150] Setting up ip1
I1216 13:23:41.500322 34688 net.cpp:157] Top shape: 64 60 (3840)
I1216 13:23:41.500339 34688 net.cpp:165] Memory required for data: 4305152
I1216 13:23:41.500367 34688 layer_factory.hpp:77] Creating layer ip2
I1216 13:23:41.500396 34688 net.cpp:100] Creating Layer ip2
I1216 13:23:41.500413 34688 net.cpp:434] ip2 <- ip1
I1216 13:23:41.500433 34688 net.cpp:408] ip2 -> ip2
I1216 13:23:41.500613 34688 net.cpp:150] Setting up ip2
I1216 13:23:41.500639 34688 net.cpp:157] Top shape: 64 2 (128)
I1216 13:23:41.500654 34688 net.cpp:165] Memory required for data: 4305664
I1216 13:23:41.500674 34688 layer_factory.hpp:77] Creating layer loss
I1216 13:23:41.500694 34688 net.cpp:100] Creating Layer loss
I1216 13:23:41.500710 34688 net.cpp:434] loss <- ip2
I1216 13:23:41.500728 34688 net.cpp:434] loss <- label
I1216 13:23:41.500752 34688 net.cpp:408] loss -> loss
I1216 13:23:41.500838 34688 net.cpp:150] Setting up loss
I1216 13:23:41.500866 34688 net.cpp:157] Top shape: (1)
I1216 13:23:41.500882 34688 net.cpp:160]     with loss weight 1
I1216 13:23:41.500931 34688 net.cpp:165] Memory required for data: 4305668
I1216 13:23:41.500948 34688 net.cpp:226] loss needs backward computation.
I1216 13:23:41.500964 34688 net.cpp:226] ip2 needs backward computation.
I1216 13:23:41.500988 34688 net.cpp:226] ip1 needs backward computation.
I1216 13:23:41.501003 34688 net.cpp:226] relu2 needs backward computation.
I1216 13:23:41.501019 34688 net.cpp:226] pool2 needs backward computation.
I1216 13:23:41.501036 34688 net.cpp:226] conv2 needs backward computation.
I1216 13:23:41.501076 34688 net.cpp:226] relu1 needs backward computation.
I1216 13:23:41.501093 34688 net.cpp:226] pool1 needs backward computation.
I1216 13:23:41.501112 34688 net.cpp:226] conv1 needs backward computation.
I1216 13:23:41.501129 34688 net.cpp:228] data does not need backward computation.
I1216 13:23:41.501145 34688 net.cpp:270] This network produces output loss
I1216 13:23:41.501171 34688 net.cpp:283] Network initialization done.
I1216 13:23:41.501682 34688 solver.cpp:193] Creating test net (#0) specified by net file: ./train_val.prototxt
I1216 13:23:41.501742 34688 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1216 13:23:41.501920 34688 net.cpp:58] Initializing net from parameters: 
name: "face_alignment_full_net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "../validation_hdf5.txt"
    batch_size: 64
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 40
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 60
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "EuclideanLoss"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1216 13:23:41.502810 34688 layer_factory.hpp:77] Creating layer data
I1216 13:23:41.502838 34688 net.cpp:100] Creating Layer data
I1216 13:23:41.502856 34688 net.cpp:408] data -> data
I1216 13:23:41.502878 34688 net.cpp:408] data -> label
I1216 13:23:41.502900 34688 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: ../validation_hdf5.txt
I1216 13:23:41.502943 34688 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1216 13:23:41.526629 34688 net.cpp:150] Setting up data
I1216 13:23:41.526728 34688 net.cpp:157] Top shape: 64 3 15 15 (43200)
I1216 13:23:41.526752 34688 net.cpp:157] Top shape: 64 2 1 1 (128)
I1216 13:23:41.526768 34688 net.cpp:165] Memory required for data: 173312
I1216 13:23:41.526790 34688 layer_factory.hpp:77] Creating layer label_data_1_split
I1216 13:23:41.526829 34688 net.cpp:100] Creating Layer label_data_1_split
I1216 13:23:41.526850 34688 net.cpp:434] label_data_1_split <- label
I1216 13:23:41.526875 34688 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1216 13:23:41.526906 34688 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1216 13:23:41.526975 34688 net.cpp:150] Setting up label_data_1_split
I1216 13:23:41.527045 34688 net.cpp:157] Top shape: 64 2 1 1 (128)
I1216 13:23:41.527065 34688 net.cpp:157] Top shape: 64 2 1 1 (128)
I1216 13:23:41.527081 34688 net.cpp:165] Memory required for data: 174336
I1216 13:23:41.527098 34688 layer_factory.hpp:77] Creating layer conv1
I1216 13:23:41.527132 34688 net.cpp:100] Creating Layer conv1
I1216 13:23:41.527149 34688 net.cpp:434] conv1 <- data
I1216 13:23:41.527169 34688 net.cpp:408] conv1 -> conv1
I1216 13:23:41.529593 34688 net.cpp:150] Setting up conv1
I1216 13:23:41.529635 34688 net.cpp:157] Top shape: 64 20 12 12 (184320)
I1216 13:23:41.529654 34688 net.cpp:165] Memory required for data: 911616
I1216 13:23:41.529691 34688 layer_factory.hpp:77] Creating layer pool1
I1216 13:23:41.529717 34688 net.cpp:100] Creating Layer pool1
I1216 13:23:41.529736 34688 net.cpp:434] pool1 <- conv1
I1216 13:23:41.529754 34688 net.cpp:408] pool1 -> pool1
I1216 13:23:41.529832 34688 net.cpp:150] Setting up pool1
I1216 13:23:41.529860 34688 net.cpp:157] Top shape: 64 20 11 11 (154880)
I1216 13:23:41.529877 34688 net.cpp:165] Memory required for data: 1531136
I1216 13:23:41.529894 34688 layer_factory.hpp:77] Creating layer relu1
I1216 13:23:41.529919 34688 net.cpp:100] Creating Layer relu1
I1216 13:23:41.529937 34688 net.cpp:434] relu1 <- pool1
I1216 13:23:41.529955 34688 net.cpp:395] relu1 -> pool1 (in-place)
I1216 13:23:41.531179 34688 net.cpp:150] Setting up relu1
I1216 13:23:41.531219 34688 net.cpp:157] Top shape: 64 20 11 11 (154880)
I1216 13:23:41.531235 34688 net.cpp:165] Memory required for data: 2150656
I1216 13:23:41.531251 34688 layer_factory.hpp:77] Creating layer conv2
I1216 13:23:41.531278 34688 net.cpp:100] Creating Layer conv2
I1216 13:23:41.531296 34688 net.cpp:434] conv2 <- pool1
I1216 13:23:41.531317 34688 net.cpp:408] conv2 -> conv2
I1216 13:23:41.533601 34688 net.cpp:150] Setting up conv2
I1216 13:23:41.533648 34688 net.cpp:157] Top shape: 64 40 9 9 (207360)
I1216 13:23:41.533665 34688 net.cpp:165] Memory required for data: 2980096
I1216 13:23:41.533691 34688 layer_factory.hpp:77] Creating layer pool2
I1216 13:23:41.533717 34688 net.cpp:100] Creating Layer pool2
I1216 13:23:41.533735 34688 net.cpp:434] pool2 <- conv2
I1216 13:23:41.533754 34688 net.cpp:408] pool2 -> pool2
I1216 13:23:41.533838 34688 net.cpp:150] Setting up pool2
I1216 13:23:41.533877 34688 net.cpp:157] Top shape: 64 40 8 8 (163840)
I1216 13:23:41.533893 34688 net.cpp:165] Memory required for data: 3635456
I1216 13:23:41.533910 34688 layer_factory.hpp:77] Creating layer relu2
I1216 13:23:41.533931 34688 net.cpp:100] Creating Layer relu2
I1216 13:23:41.533946 34688 net.cpp:434] relu2 <- pool2
I1216 13:23:41.533967 34688 net.cpp:395] relu2 -> pool2 (in-place)
I1216 13:23:41.534238 34688 net.cpp:150] Setting up relu2
I1216 13:23:41.534276 34688 net.cpp:157] Top shape: 64 40 8 8 (163840)
I1216 13:23:41.534291 34688 net.cpp:165] Memory required for data: 4290816
I1216 13:23:41.534307 34688 layer_factory.hpp:77] Creating layer ip1
I1216 13:23:41.534334 34688 net.cpp:100] Creating Layer ip1
I1216 13:23:41.534358 34688 net.cpp:434] ip1 <- pool2
I1216 13:23:41.534379 34688 net.cpp:408] ip1 -> ip1
I1216 13:23:41.542248 34688 net.cpp:150] Setting up ip1
I1216 13:23:41.542281 34688 net.cpp:157] Top shape: 64 60 (3840)
I1216 13:23:41.542299 34688 net.cpp:165] Memory required for data: 4306176
I1216 13:23:41.542322 34688 layer_factory.hpp:77] Creating layer ip2
I1216 13:23:41.542347 34688 net.cpp:100] Creating Layer ip2
I1216 13:23:41.542371 34688 net.cpp:434] ip2 <- ip1
I1216 13:23:41.542392 34688 net.cpp:408] ip2 -> ip2
I1216 13:23:41.542570 34688 net.cpp:150] Setting up ip2
I1216 13:23:41.542598 34688 net.cpp:157] Top shape: 64 2 (128)
I1216 13:23:41.542613 34688 net.cpp:165] Memory required for data: 4306688
I1216 13:23:41.542631 34688 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1216 13:23:41.542654 34688 net.cpp:100] Creating Layer ip2_ip2_0_split
I1216 13:23:41.542670 34688 net.cpp:434] ip2_ip2_0_split <- ip2
I1216 13:23:41.542687 34688 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1216 13:23:41.542743 34688 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1216 13:23:41.542812 34688 net.cpp:150] Setting up ip2_ip2_0_split
I1216 13:23:41.542837 34688 net.cpp:157] Top shape: 64 2 (128)
I1216 13:23:41.542860 34688 net.cpp:157] Top shape: 64 2 (128)
I1216 13:23:41.542875 34688 net.cpp:165] Memory required for data: 4307712
I1216 13:23:41.542891 34688 layer_factory.hpp:77] Creating layer accuracy
I1216 13:23:41.542914 34688 net.cpp:100] Creating Layer accuracy
I1216 13:23:41.542929 34688 net.cpp:434] accuracy <- ip2_ip2_0_split_0
I1216 13:23:41.542946 34688 net.cpp:434] accuracy <- label_data_1_split_0
I1216 13:23:41.542968 34688 net.cpp:408] accuracy -> accuracy
I1216 13:23:41.543036 34688 net.cpp:150] Setting up accuracy
I1216 13:23:41.543059 34688 net.cpp:157] Top shape: (1)
I1216 13:23:41.543074 34688 net.cpp:160]     with loss weight 1
I1216 13:23:41.543109 34688 net.cpp:165] Memory required for data: 4307716
I1216 13:23:41.543124 34688 layer_factory.hpp:77] Creating layer loss
I1216 13:23:41.543143 34688 net.cpp:100] Creating Layer loss
I1216 13:23:41.543157 34688 net.cpp:434] loss <- ip2_ip2_0_split_1
I1216 13:23:41.543174 34688 net.cpp:434] loss <- label_data_1_split_1
I1216 13:23:41.543192 34688 net.cpp:408] loss -> loss
I1216 13:23:41.543265 34688 net.cpp:150] Setting up loss
I1216 13:23:41.543288 34688 net.cpp:157] Top shape: (1)
I1216 13:23:41.543303 34688 net.cpp:160]     with loss weight 1
I1216 13:23:41.543321 34688 net.cpp:165] Memory required for data: 4307720
I1216 13:23:41.543337 34688 net.cpp:226] loss needs backward computation.
I1216 13:23:41.543354 34688 net.cpp:226] accuracy needs backward computation.
I1216 13:23:41.543370 34688 net.cpp:226] ip2_ip2_0_split needs backward computation.
I1216 13:23:41.543383 34688 net.cpp:226] ip2 needs backward computation.
I1216 13:23:41.543397 34688 net.cpp:226] ip1 needs backward computation.
I1216 13:23:41.543412 34688 net.cpp:226] relu2 needs backward computation.
I1216 13:23:41.543426 34688 net.cpp:226] pool2 needs backward computation.
I1216 13:23:41.543440 34688 net.cpp:226] conv2 needs backward computation.
I1216 13:23:41.543454 34688 net.cpp:226] relu1 needs backward computation.
I1216 13:23:41.543468 34688 net.cpp:226] pool1 needs backward computation.
I1216 13:23:41.543483 34688 net.cpp:226] conv1 needs backward computation.
I1216 13:23:41.543498 34688 net.cpp:228] label_data_1_split does not need backward computation.
I1216 13:23:41.543514 34688 net.cpp:228] data does not need backward computation.
I1216 13:23:41.543529 34688 net.cpp:270] This network produces output accuracy
I1216 13:23:41.543542 34688 net.cpp:270] This network produces output loss
I1216 13:23:41.543570 34688 net.cpp:283] Network initialization done.
I1216 13:23:41.543659 34688 solver.cpp:72] Solver scaffolding done.
I1216 13:23:41.544116 34688 caffe.cpp:251] Starting Optimization
I1216 13:23:41.544145 34688 solver.cpp:291] Solving face_alignment_full_net
I1216 13:23:41.544159 34688 solver.cpp:292] Learning Rate Policy: step
I1216 13:23:41.546448 34688 solver.cpp:349] Iteration 0, Testing net (#0)
I1216 13:23:41.981325 34688 solver.cpp:416]     Test net output #0: accuracy = 60.676 (* 1 = 60.676 loss)
I1216 13:23:41.981408 34688 solver.cpp:416]     Test net output #1: loss = 60.676 (* 1 = 60.676 loss)
I1216 13:23:41.988698 34688 solver.cpp:240] Iteration 0, loss = 57.7178
I1216 13:23:41.988752 34688 solver.cpp:256]     Train net output #0: loss = 57.7178 (* 1 = 57.7178 loss)
I1216 13:23:41.988787 34688 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I1216 13:23:45.266415 34688 solver.cpp:349] Iteration 1000, Testing net (#0)
I1216 13:23:45.708783 34688 solver.cpp:416]     Test net output #0: accuracy = 6.45784 (* 1 = 6.45784 loss)
I1216 13:23:45.708866 34688 solver.cpp:416]     Test net output #1: loss = 6.45784 (* 1 = 6.45784 loss)
I1216 13:23:45.711410 34688 solver.cpp:240] Iteration 1000, loss = 7.55124
I1216 13:23:45.711462 34688 solver.cpp:256]     Train net output #0: loss = 7.55124 (* 1 = 7.55124 loss)
I1216 13:23:45.711491 34688 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I1216 13:23:49.181991 34688 solver.cpp:349] Iteration 2000, Testing net (#0)
I1216 13:23:49.645618 34688 solver.cpp:416]     Test net output #0: accuracy = 6.1695 (* 1 = 6.1695 loss)
I1216 13:23:49.645709 34688 solver.cpp:416]     Test net output #1: loss = 6.1695 (* 1 = 6.1695 loss)
I1216 13:23:49.653137 34688 solver.cpp:240] Iteration 2000, loss = 6.56485
I1216 13:23:49.653187 34688 solver.cpp:256]     Train net output #0: loss = 6.56485 (* 1 = 6.56485 loss)
I1216 13:23:49.653215 34688 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I1216 13:23:53.146898 34688 solver.cpp:349] Iteration 3000, Testing net (#0)
I1216 13:23:53.617053 34688 solver.cpp:416]     Test net output #0: accuracy = 5.96898 (* 1 = 5.96898 loss)
I1216 13:23:53.617138 34688 solver.cpp:416]     Test net output #1: loss = 5.96898 (* 1 = 5.96898 loss)
I1216 13:23:53.619534 34688 solver.cpp:240] Iteration 3000, loss = 7.81832
I1216 13:23:53.619582 34688 solver.cpp:256]     Train net output #0: loss = 7.81832 (* 1 = 7.81832 loss)
I1216 13:23:53.619607 34688 sgd_solver.cpp:106] Iteration 3000, lr = 1e-05
I1216 13:23:56.840373 34688 solver.cpp:349] Iteration 4000, Testing net (#0)
I1216 13:23:57.280091 34688 solver.cpp:416]     Test net output #0: accuracy = 5.80198 (* 1 = 5.80198 loss)
I1216 13:23:57.280169 34688 solver.cpp:416]     Test net output #1: loss = 5.80198 (* 1 = 5.80198 loss)
I1216 13:23:57.282572 34688 solver.cpp:240] Iteration 4000, loss = 7.01566
I1216 13:23:57.282620 34688 solver.cpp:256]     Train net output #0: loss = 7.01566 (* 1 = 7.01566 loss)
I1216 13:23:57.282645 34688 sgd_solver.cpp:106] Iteration 4000, lr = 1e-05
I1216 13:24:00.551895 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_5000.caffemodel
I1216 13:24:00.556478 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_5000.solverstate
I1216 13:24:00.572540 34688 solver.cpp:349] Iteration 5000, Testing net (#0)
I1216 13:24:01.043198 34688 solver.cpp:416]     Test net output #0: accuracy = 5.65079 (* 1 = 5.65079 loss)
I1216 13:24:01.043283 34688 solver.cpp:416]     Test net output #1: loss = 5.65079 (* 1 = 5.65079 loss)
I1216 13:24:01.082891 34688 solver.cpp:240] Iteration 5000, loss = 5.41326
I1216 13:24:01.083019 34688 solver.cpp:256]     Train net output #0: loss = 5.41326 (* 1 = 5.41326 loss)
I1216 13:24:01.083046 34688 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I1216 13:24:04.290573 34688 solver.cpp:349] Iteration 6000, Testing net (#0)
I1216 13:24:04.726119 34688 solver.cpp:416]     Test net output #0: accuracy = 5.54399 (* 1 = 5.54399 loss)
I1216 13:24:04.726199 34688 solver.cpp:416]     Test net output #1: loss = 5.54399 (* 1 = 5.54399 loss)
I1216 13:24:04.728569 34688 solver.cpp:240] Iteration 6000, loss = 6.11722
I1216 13:24:04.728618 34688 solver.cpp:256]     Train net output #0: loss = 6.11722 (* 1 = 6.11722 loss)
I1216 13:24:04.728644 34688 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I1216 13:24:07.963095 34688 solver.cpp:349] Iteration 7000, Testing net (#0)
I1216 13:24:08.382601 34688 solver.cpp:416]     Test net output #0: accuracy = 5.39414 (* 1 = 5.39414 loss)
I1216 13:24:08.382685 34688 solver.cpp:416]     Test net output #1: loss = 5.39414 (* 1 = 5.39414 loss)
I1216 13:24:08.385054 34688 solver.cpp:240] Iteration 7000, loss = 5.8128
I1216 13:24:08.385102 34688 solver.cpp:256]     Train net output #0: loss = 5.8128 (* 1 = 5.8128 loss)
I1216 13:24:08.385128 34688 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I1216 13:24:11.832289 34688 solver.cpp:349] Iteration 8000, Testing net (#0)
I1216 13:24:12.267402 34688 solver.cpp:416]     Test net output #0: accuracy = 5.2884 (* 1 = 5.2884 loss)
I1216 13:24:12.267487 34688 solver.cpp:416]     Test net output #1: loss = 5.2884 (* 1 = 5.2884 loss)
I1216 13:24:12.269951 34688 solver.cpp:240] Iteration 8000, loss = 7.47339
I1216 13:24:12.270001 34688 solver.cpp:256]     Train net output #0: loss = 7.47339 (* 1 = 7.47339 loss)
I1216 13:24:12.270030 34688 sgd_solver.cpp:106] Iteration 8000, lr = 1e-05
I1216 13:24:15.439214 34688 solver.cpp:349] Iteration 9000, Testing net (#0)
I1216 13:24:15.874765 34688 solver.cpp:416]     Test net output #0: accuracy = 5.11176 (* 1 = 5.11176 loss)
I1216 13:24:15.874850 34688 solver.cpp:416]     Test net output #1: loss = 5.11176 (* 1 = 5.11176 loss)
I1216 13:24:15.877213 34688 solver.cpp:240] Iteration 9000, loss = 6.49742
I1216 13:24:15.877261 34688 solver.cpp:256]     Train net output #0: loss = 6.49742 (* 1 = 6.49742 loss)
I1216 13:24:15.877286 34688 sgd_solver.cpp:106] Iteration 9000, lr = 1e-05
I1216 13:24:20.543689 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_10000.caffemodel
I1216 13:24:20.547667 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_10000.solverstate
I1216 13:24:20.549623 34688 solver.cpp:349] Iteration 10000, Testing net (#0)
I1216 13:24:22.787395 34688 solver.cpp:416]     Test net output #0: accuracy = 4.874 (* 1 = 4.874 loss)
I1216 13:24:22.787477 34688 solver.cpp:416]     Test net output #1: loss = 4.874 (* 1 = 4.874 loss)
I1216 13:24:22.838665 34688 solver.cpp:240] Iteration 10000, loss = 4.60295
I1216 13:24:22.838776 34688 solver.cpp:256]     Train net output #0: loss = 4.60295 (* 1 = 4.60295 loss)
I1216 13:24:22.838804 34688 sgd_solver.cpp:106] Iteration 10000, lr = 8e-06
I1216 13:24:33.147702 34688 solver.cpp:349] Iteration 11000, Testing net (#0)
I1216 13:24:35.011787 34688 solver.cpp:416]     Test net output #0: accuracy = 4.67647 (* 1 = 4.67647 loss)
I1216 13:24:35.011871 34688 solver.cpp:416]     Test net output #1: loss = 4.67647 (* 1 = 4.67647 loss)
I1216 13:24:35.025583 34688 solver.cpp:240] Iteration 11000, loss = 4.99033
I1216 13:24:35.025638 34688 solver.cpp:256]     Train net output #0: loss = 4.99033 (* 1 = 4.99033 loss)
I1216 13:24:35.025666 34688 sgd_solver.cpp:106] Iteration 11000, lr = 8e-06
I1216 13:24:45.407260 34688 solver.cpp:349] Iteration 12000, Testing net (#0)
I1216 13:24:47.416034 34688 solver.cpp:416]     Test net output #0: accuracy = 4.36848 (* 1 = 4.36848 loss)
I1216 13:24:47.416116 34688 solver.cpp:416]     Test net output #1: loss = 4.36848 (* 1 = 4.36848 loss)
I1216 13:24:47.427047 34688 solver.cpp:240] Iteration 12000, loss = 4.50285
I1216 13:24:47.427094 34688 solver.cpp:256]     Train net output #0: loss = 4.50285 (* 1 = 4.50285 loss)
I1216 13:24:47.427119 34688 sgd_solver.cpp:106] Iteration 12000, lr = 8e-06
I1216 13:24:57.918184 34688 solver.cpp:349] Iteration 13000, Testing net (#0)
I1216 13:24:59.917881 34688 solver.cpp:416]     Test net output #0: accuracy = 4.07072 (* 1 = 4.07072 loss)
I1216 13:24:59.917968 34688 solver.cpp:416]     Test net output #1: loss = 4.07072 (* 1 = 4.07072 loss)
I1216 13:24:59.928946 34688 solver.cpp:240] Iteration 13000, loss = 5.8157
I1216 13:24:59.928993 34688 solver.cpp:256]     Train net output #0: loss = 5.8157 (* 1 = 5.8157 loss)
I1216 13:24:59.929021 34688 sgd_solver.cpp:106] Iteration 13000, lr = 8e-06
I1216 13:25:10.354790 34688 solver.cpp:349] Iteration 14000, Testing net (#0)
I1216 13:25:12.349416 34688 solver.cpp:416]     Test net output #0: accuracy = 3.82063 (* 1 = 3.82063 loss)
I1216 13:25:12.349500 34688 solver.cpp:416]     Test net output #1: loss = 3.82063 (* 1 = 3.82063 loss)
I1216 13:25:12.360420 34688 solver.cpp:240] Iteration 14000, loss = 5.21446
I1216 13:25:12.360466 34688 solver.cpp:256]     Train net output #0: loss = 5.21446 (* 1 = 5.21446 loss)
I1216 13:25:12.360491 34688 sgd_solver.cpp:106] Iteration 14000, lr = 8e-06
I1216 13:25:23.391362 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_15000.caffemodel
I1216 13:25:23.395727 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_15000.solverstate
I1216 13:25:23.397794 34688 solver.cpp:349] Iteration 15000, Testing net (#0)
I1216 13:25:25.438019 34688 solver.cpp:416]     Test net output #0: accuracy = 3.6237 (* 1 = 3.6237 loss)
I1216 13:25:25.438112 34688 solver.cpp:416]     Test net output #1: loss = 3.6237 (* 1 = 3.6237 loss)
I1216 13:25:25.498857 34688 solver.cpp:240] Iteration 15000, loss = 3.2985
I1216 13:25:25.498971 34688 solver.cpp:256]     Train net output #0: loss = 3.2985 (* 1 = 3.2985 loss)
I1216 13:25:25.498999 34688 sgd_solver.cpp:106] Iteration 15000, lr = 8e-06
I1216 13:25:36.988808 34688 solver.cpp:349] Iteration 16000, Testing net (#0)
I1216 13:25:39.016314 34688 solver.cpp:416]     Test net output #0: accuracy = 3.49725 (* 1 = 3.49725 loss)
I1216 13:25:39.016398 34688 solver.cpp:416]     Test net output #1: loss = 3.49725 (* 1 = 3.49725 loss)
I1216 13:25:39.027256 34688 solver.cpp:240] Iteration 16000, loss = 3.36175
I1216 13:25:39.027303 34688 solver.cpp:256]     Train net output #0: loss = 3.36175 (* 1 = 3.36175 loss)
I1216 13:25:39.027328 34688 sgd_solver.cpp:106] Iteration 16000, lr = 8e-06
I1216 13:25:49.775421 34688 solver.cpp:349] Iteration 17000, Testing net (#0)
I1216 13:25:51.794080 34688 solver.cpp:416]     Test net output #0: accuracy = 3.39355 (* 1 = 3.39355 loss)
I1216 13:25:51.794165 34688 solver.cpp:416]     Test net output #1: loss = 3.39355 (* 1 = 3.39355 loss)
I1216 13:25:51.810667 34688 solver.cpp:240] Iteration 17000, loss = 2.99455
I1216 13:25:51.810724 34688 solver.cpp:256]     Train net output #0: loss = 2.99455 (* 1 = 2.99455 loss)
I1216 13:25:51.810748 34688 sgd_solver.cpp:106] Iteration 17000, lr = 8e-06
I1216 13:26:02.724587 34688 solver.cpp:349] Iteration 18000, Testing net (#0)
I1216 13:26:04.759789 34688 solver.cpp:416]     Test net output #0: accuracy = 3.32501 (* 1 = 3.32501 loss)
I1216 13:26:04.759883 34688 solver.cpp:416]     Test net output #1: loss = 3.32501 (* 1 = 3.32501 loss)
I1216 13:26:04.771289 34688 solver.cpp:240] Iteration 18000, loss = 4.1609
I1216 13:26:04.771342 34688 solver.cpp:256]     Train net output #0: loss = 4.1609 (* 1 = 4.1609 loss)
I1216 13:26:04.771368 34688 sgd_solver.cpp:106] Iteration 18000, lr = 8e-06
I1216 13:26:16.300146 34688 solver.cpp:349] Iteration 19000, Testing net (#0)
I1216 13:26:18.301563 34688 solver.cpp:416]     Test net output #0: accuracy = 3.2676 (* 1 = 3.2676 loss)
I1216 13:26:18.301648 34688 solver.cpp:416]     Test net output #1: loss = 3.2676 (* 1 = 3.2676 loss)
I1216 13:26:18.312602 34688 solver.cpp:240] Iteration 19000, loss = 4.65085
I1216 13:26:18.312650 34688 solver.cpp:256]     Train net output #0: loss = 4.65085 (* 1 = 4.65085 loss)
I1216 13:26:18.312680 34688 sgd_solver.cpp:106] Iteration 19000, lr = 8e-06
I1216 13:26:29.959429 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_20000.caffemodel
I1216 13:26:29.963359 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_20000.solverstate
I1216 13:26:29.965345 34688 solver.cpp:349] Iteration 20000, Testing net (#0)
I1216 13:26:31.995610 34688 solver.cpp:416]     Test net output #0: accuracy = 3.22204 (* 1 = 3.22204 loss)
I1216 13:26:31.995694 34688 solver.cpp:416]     Test net output #1: loss = 3.22204 (* 1 = 3.22204 loss)
I1216 13:26:32.049783 34688 solver.cpp:240] Iteration 20000, loss = 2.95792
I1216 13:26:32.049901 34688 solver.cpp:256]     Train net output #0: loss = 2.95792 (* 1 = 2.95792 loss)
I1216 13:26:32.049928 34688 sgd_solver.cpp:106] Iteration 20000, lr = 6.4e-06
I1216 13:26:43.698204 34688 solver.cpp:349] Iteration 21000, Testing net (#0)
I1216 13:26:45.709697 34688 solver.cpp:416]     Test net output #0: accuracy = 3.19274 (* 1 = 3.19274 loss)
I1216 13:26:45.709780 34688 solver.cpp:416]     Test net output #1: loss = 3.19274 (* 1 = 3.19274 loss)
I1216 13:26:45.720679 34688 solver.cpp:240] Iteration 21000, loss = 2.81319
I1216 13:26:45.720727 34688 solver.cpp:256]     Train net output #0: loss = 2.8132 (* 1 = 2.8132 loss)
I1216 13:26:45.720753 34688 sgd_solver.cpp:106] Iteration 21000, lr = 6.4e-06
I1216 13:26:57.354197 34688 solver.cpp:349] Iteration 22000, Testing net (#0)
I1216 13:26:59.365365 34688 solver.cpp:416]     Test net output #0: accuracy = 3.15996 (* 1 = 3.15996 loss)
I1216 13:26:59.365453 34688 solver.cpp:416]     Test net output #1: loss = 3.15996 (* 1 = 3.15996 loss)
I1216 13:26:59.376421 34688 solver.cpp:240] Iteration 22000, loss = 2.69662
I1216 13:26:59.376469 34688 solver.cpp:256]     Train net output #0: loss = 2.69662 (* 1 = 2.69662 loss)
I1216 13:26:59.376497 34688 sgd_solver.cpp:106] Iteration 22000, lr = 6.4e-06
I1216 13:27:10.647208 34688 solver.cpp:349] Iteration 23000, Testing net (#0)
I1216 13:27:12.641491 34688 solver.cpp:416]     Test net output #0: accuracy = 3.14041 (* 1 = 3.14041 loss)
I1216 13:27:12.641584 34688 solver.cpp:416]     Test net output #1: loss = 3.14041 (* 1 = 3.14041 loss)
I1216 13:27:12.652482 34688 solver.cpp:240] Iteration 23000, loss = 3.83895
I1216 13:27:12.652530 34688 solver.cpp:256]     Train net output #0: loss = 3.83895 (* 1 = 3.83895 loss)
I1216 13:27:12.652554 34688 sgd_solver.cpp:106] Iteration 23000, lr = 6.4e-06
I1216 13:27:23.076828 34688 solver.cpp:349] Iteration 24000, Testing net (#0)
I1216 13:27:25.165760 34688 solver.cpp:416]     Test net output #0: accuracy = 3.12527 (* 1 = 3.12527 loss)
I1216 13:27:25.165870 34688 solver.cpp:416]     Test net output #1: loss = 3.12527 (* 1 = 3.12527 loss)
I1216 13:27:25.168233 34688 solver.cpp:240] Iteration 24000, loss = 4.50739
I1216 13:27:25.168283 34688 solver.cpp:256]     Train net output #0: loss = 4.50739 (* 1 = 4.50739 loss)
I1216 13:27:25.168309 34688 sgd_solver.cpp:106] Iteration 24000, lr = 6.4e-06
I1216 13:27:35.442940 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_25000.caffemodel
I1216 13:27:35.446892 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_25000.solverstate
I1216 13:27:35.448870 34688 solver.cpp:349] Iteration 25000, Testing net (#0)
I1216 13:27:37.473562 34688 solver.cpp:416]     Test net output #0: accuracy = 3.09728 (* 1 = 3.09728 loss)
I1216 13:27:37.473642 34688 solver.cpp:416]     Test net output #1: loss = 3.09728 (* 1 = 3.09728 loss)
I1216 13:27:37.525615 34688 solver.cpp:240] Iteration 25000, loss = 2.84492
I1216 13:27:37.525727 34688 solver.cpp:256]     Train net output #0: loss = 2.84492 (* 1 = 2.84492 loss)
I1216 13:27:37.525755 34688 sgd_solver.cpp:106] Iteration 25000, lr = 6.4e-06
I1216 13:27:47.924891 34688 solver.cpp:349] Iteration 26000, Testing net (#0)
I1216 13:27:49.924124 34688 solver.cpp:416]     Test net output #0: accuracy = 3.08588 (* 1 = 3.08588 loss)
I1216 13:27:49.924206 34688 solver.cpp:416]     Test net output #1: loss = 3.08588 (* 1 = 3.08588 loss)
I1216 13:27:49.935066 34688 solver.cpp:240] Iteration 26000, loss = 2.63987
I1216 13:27:49.935112 34688 solver.cpp:256]     Train net output #0: loss = 2.63987 (* 1 = 2.63987 loss)
I1216 13:27:49.935137 34688 sgd_solver.cpp:106] Iteration 26000, lr = 6.4e-06
I1216 13:28:00.313899 34688 solver.cpp:349] Iteration 27000, Testing net (#0)
I1216 13:28:02.332890 34688 solver.cpp:416]     Test net output #0: accuracy = 3.06785 (* 1 = 3.06785 loss)
I1216 13:28:02.332973 34688 solver.cpp:416]     Test net output #1: loss = 3.06785 (* 1 = 3.06785 loss)
I1216 13:28:02.335326 34688 solver.cpp:240] Iteration 27000, loss = 2.58339
I1216 13:28:02.335376 34688 solver.cpp:256]     Train net output #0: loss = 2.58339 (* 1 = 2.58339 loss)
I1216 13:28:02.335400 34688 sgd_solver.cpp:106] Iteration 27000, lr = 6.4e-06
I1216 13:28:12.732421 34688 solver.cpp:349] Iteration 28000, Testing net (#0)
I1216 13:28:14.880945 34688 solver.cpp:416]     Test net output #0: accuracy = 3.05125 (* 1 = 3.05125 loss)
I1216 13:28:14.881038 34688 solver.cpp:416]     Test net output #1: loss = 3.05125 (* 1 = 3.05125 loss)
I1216 13:28:14.891983 34688 solver.cpp:240] Iteration 28000, loss = 3.71799
I1216 13:28:14.892031 34688 solver.cpp:256]     Train net output #0: loss = 3.71799 (* 1 = 3.71799 loss)
I1216 13:28:14.892057 34688 sgd_solver.cpp:106] Iteration 28000, lr = 6.4e-06
I1216 13:28:25.101817 34688 solver.cpp:349] Iteration 29000, Testing net (#0)
I1216 13:28:27.243046 34688 solver.cpp:416]     Test net output #0: accuracy = 3.02451 (* 1 = 3.02451 loss)
I1216 13:28:27.243129 34688 solver.cpp:416]     Test net output #1: loss = 3.02451 (* 1 = 3.02451 loss)
I1216 13:28:27.253947 34688 solver.cpp:240] Iteration 29000, loss = 4.41797
I1216 13:28:27.253994 34688 solver.cpp:256]     Train net output #0: loss = 4.41797 (* 1 = 4.41797 loss)
I1216 13:28:27.254019 34688 sgd_solver.cpp:106] Iteration 29000, lr = 6.4e-06
I1216 13:28:37.581923 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_30000.caffemodel
I1216 13:28:37.586136 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_30000.solverstate
I1216 13:28:37.589105 34688 solver.cpp:349] Iteration 30000, Testing net (#0)
I1216 13:28:39.572098 34688 solver.cpp:416]     Test net output #0: accuracy = 3.02059 (* 1 = 3.02059 loss)
I1216 13:28:39.572185 34688 solver.cpp:416]     Test net output #1: loss = 3.02059 (* 1 = 3.02059 loss)
I1216 13:28:39.626227 34688 solver.cpp:240] Iteration 30000, loss = 2.7487
I1216 13:28:39.626338 34688 solver.cpp:256]     Train net output #0: loss = 2.7487 (* 1 = 2.7487 loss)
I1216 13:28:39.626370 34688 sgd_solver.cpp:106] Iteration 30000, lr = 5.12e-06
I1216 13:28:50.884763 34688 solver.cpp:349] Iteration 31000, Testing net (#0)
I1216 13:28:53.009060 34688 solver.cpp:416]     Test net output #0: accuracy = 3.00884 (* 1 = 3.00884 loss)
I1216 13:28:53.009142 34688 solver.cpp:416]     Test net output #1: loss = 3.00884 (* 1 = 3.00884 loss)
I1216 13:28:53.020094 34688 solver.cpp:240] Iteration 31000, loss = 2.53166
I1216 13:28:53.020166 34688 solver.cpp:256]     Train net output #0: loss = 2.53166 (* 1 = 2.53166 loss)
I1216 13:28:53.020193 34688 sgd_solver.cpp:106] Iteration 31000, lr = 5.12e-06
I1216 13:29:04.607746 34688 solver.cpp:349] Iteration 32000, Testing net (#0)
I1216 13:29:06.690881 34688 solver.cpp:416]     Test net output #0: accuracy = 2.98845 (* 1 = 2.98845 loss)
I1216 13:29:06.690953 34688 solver.cpp:416]     Test net output #1: loss = 2.98845 (* 1 = 2.98845 loss)
I1216 13:29:06.701984 34688 solver.cpp:240] Iteration 32000, loss = 2.51234
I1216 13:29:06.702054 34688 solver.cpp:256]     Train net output #0: loss = 2.51234 (* 1 = 2.51234 loss)
I1216 13:29:06.702081 34688 sgd_solver.cpp:106] Iteration 32000, lr = 5.12e-06
I1216 13:29:18.217788 34688 solver.cpp:349] Iteration 33000, Testing net (#0)
I1216 13:29:20.332388 34688 solver.cpp:416]     Test net output #0: accuracy = 2.98436 (* 1 = 2.98436 loss)
I1216 13:29:20.332459 34688 solver.cpp:416]     Test net output #1: loss = 2.98436 (* 1 = 2.98436 loss)
I1216 13:29:20.343503 34688 solver.cpp:240] Iteration 33000, loss = 3.63185
I1216 13:29:20.343559 34688 solver.cpp:256]     Train net output #0: loss = 3.63186 (* 1 = 3.63186 loss)
I1216 13:29:20.343586 34688 sgd_solver.cpp:106] Iteration 33000, lr = 5.12e-06
I1216 13:29:32.002318 34688 solver.cpp:349] Iteration 34000, Testing net (#0)
I1216 13:29:34.113979 34688 solver.cpp:416]     Test net output #0: accuracy = 2.96302 (* 1 = 2.96302 loss)
I1216 13:29:34.114064 34688 solver.cpp:416]     Test net output #1: loss = 2.96302 (* 1 = 2.96302 loss)
I1216 13:29:34.124604 34688 solver.cpp:240] Iteration 34000, loss = 4.36042
I1216 13:29:34.124651 34688 solver.cpp:256]     Train net output #0: loss = 4.36042 (* 1 = 4.36042 loss)
I1216 13:29:34.124680 34688 sgd_solver.cpp:106] Iteration 34000, lr = 5.12e-06
I1216 13:29:45.684412 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_35000.caffemodel
I1216 13:29:45.688282 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_35000.solverstate
I1216 13:29:45.690289 34688 solver.cpp:349] Iteration 35000, Testing net (#0)
I1216 13:29:47.757472 34688 solver.cpp:416]     Test net output #0: accuracy = 2.95649 (* 1 = 2.95649 loss)
I1216 13:29:47.757563 34688 solver.cpp:416]     Test net output #1: loss = 2.95649 (* 1 = 2.95649 loss)
I1216 13:29:47.797781 34688 solver.cpp:240] Iteration 35000, loss = 2.67005
I1216 13:29:47.797894 34688 solver.cpp:256]     Train net output #0: loss = 2.67005 (* 1 = 2.67005 loss)
I1216 13:29:47.797924 34688 sgd_solver.cpp:106] Iteration 35000, lr = 5.12e-06
I1216 13:29:59.261891 34688 solver.cpp:349] Iteration 36000, Testing net (#0)
I1216 13:30:01.399847 34688 solver.cpp:416]     Test net output #0: accuracy = 2.94746 (* 1 = 2.94746 loss)
I1216 13:30:01.399929 34688 solver.cpp:416]     Test net output #1: loss = 2.94746 (* 1 = 2.94746 loss)
I1216 13:30:01.410411 34688 solver.cpp:240] Iteration 36000, loss = 2.45112
I1216 13:30:01.410459 34688 solver.cpp:256]     Train net output #0: loss = 2.45112 (* 1 = 2.45112 loss)
I1216 13:30:01.410486 34688 sgd_solver.cpp:106] Iteration 36000, lr = 5.12e-06
I1216 13:30:12.826333 34688 solver.cpp:349] Iteration 37000, Testing net (#0)
I1216 13:30:14.940178 34688 solver.cpp:416]     Test net output #0: accuracy = 2.93558 (* 1 = 2.93558 loss)
I1216 13:30:14.940261 34688 solver.cpp:416]     Test net output #1: loss = 2.93558 (* 1 = 2.93558 loss)
I1216 13:30:14.950811 34688 solver.cpp:240] Iteration 37000, loss = 2.46182
I1216 13:30:14.950860 34688 solver.cpp:256]     Train net output #0: loss = 2.46182 (* 1 = 2.46182 loss)
I1216 13:30:14.950889 34688 sgd_solver.cpp:106] Iteration 37000, lr = 5.12e-06
I1216 13:30:25.326184 34688 solver.cpp:349] Iteration 38000, Testing net (#0)
I1216 13:30:27.463345 34688 solver.cpp:416]     Test net output #0: accuracy = 2.91273 (* 1 = 2.91273 loss)
I1216 13:30:27.463428 34688 solver.cpp:416]     Test net output #1: loss = 2.91273 (* 1 = 2.91273 loss)
I1216 13:30:27.479627 34688 solver.cpp:240] Iteration 38000, loss = 3.5556
I1216 13:30:27.479684 34688 solver.cpp:256]     Train net output #0: loss = 3.5556 (* 1 = 3.5556 loss)
I1216 13:30:27.479712 34688 sgd_solver.cpp:106] Iteration 38000, lr = 5.12e-06
I1216 13:30:37.823815 34688 solver.cpp:349] Iteration 39000, Testing net (#0)
I1216 13:30:39.868165 34688 solver.cpp:416]     Test net output #0: accuracy = 2.89301 (* 1 = 2.89301 loss)
I1216 13:30:39.868269 34688 solver.cpp:416]     Test net output #1: loss = 2.89301 (* 1 = 2.89301 loss)
I1216 13:30:39.879392 34688 solver.cpp:240] Iteration 39000, loss = 4.29595
I1216 13:30:39.879442 34688 solver.cpp:256]     Train net output #0: loss = 4.29596 (* 1 = 4.29596 loss)
I1216 13:30:39.879467 34688 sgd_solver.cpp:106] Iteration 39000, lr = 5.12e-06
I1216 13:30:50.236070 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_40000.caffemodel
I1216 13:30:50.240156 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_40000.solverstate
I1216 13:30:50.242136 34688 solver.cpp:349] Iteration 40000, Testing net (#0)
I1216 13:30:52.353269 34688 solver.cpp:416]     Test net output #0: accuracy = 2.89273 (* 1 = 2.89273 loss)
I1216 13:30:52.353353 34688 solver.cpp:416]     Test net output #1: loss = 2.89273 (* 1 = 2.89273 loss)
I1216 13:30:52.405845 34688 solver.cpp:240] Iteration 40000, loss = 2.58002
I1216 13:30:52.405961 34688 solver.cpp:256]     Train net output #0: loss = 2.58002 (* 1 = 2.58002 loss)
I1216 13:30:52.405989 34688 sgd_solver.cpp:106] Iteration 40000, lr = 4.096e-06
I1216 13:31:02.664120 34688 solver.cpp:349] Iteration 41000, Testing net (#0)
I1216 13:31:04.798574 34688 solver.cpp:416]     Test net output #0: accuracy = 2.88284 (* 1 = 2.88284 loss)
I1216 13:31:04.798656 34688 solver.cpp:416]     Test net output #1: loss = 2.88284 (* 1 = 2.88284 loss)
I1216 13:31:04.809118 34688 solver.cpp:240] Iteration 41000, loss = 2.37534
I1216 13:31:04.809165 34688 solver.cpp:256]     Train net output #0: loss = 2.37534 (* 1 = 2.37534 loss)
I1216 13:31:04.809195 34688 sgd_solver.cpp:106] Iteration 41000, lr = 4.096e-06
I1216 13:31:15.073056 34688 solver.cpp:349] Iteration 42000, Testing net (#0)
I1216 13:31:17.154642 34688 solver.cpp:416]     Test net output #0: accuracy = 2.85258 (* 1 = 2.85258 loss)
I1216 13:31:17.154729 34688 solver.cpp:416]     Test net output #1: loss = 2.85258 (* 1 = 2.85258 loss)
I1216 13:31:17.165196 34688 solver.cpp:240] Iteration 42000, loss = 2.42108
I1216 13:31:17.165244 34688 solver.cpp:256]     Train net output #0: loss = 2.42108 (* 1 = 2.42108 loss)
I1216 13:31:17.165272 34688 sgd_solver.cpp:106] Iteration 42000, lr = 4.096e-06
I1216 13:31:27.617852 34688 solver.cpp:349] Iteration 43000, Testing net (#0)
I1216 13:31:29.606340 34688 solver.cpp:416]     Test net output #0: accuracy = 2.86347 (* 1 = 2.86347 loss)
I1216 13:31:29.606421 34688 solver.cpp:416]     Test net output #1: loss = 2.86347 (* 1 = 2.86347 loss)
I1216 13:31:29.616891 34688 solver.cpp:240] Iteration 43000, loss = 3.48842
I1216 13:31:29.616938 34688 solver.cpp:256]     Train net output #0: loss = 3.48842 (* 1 = 3.48842 loss)
I1216 13:31:29.616966 34688 sgd_solver.cpp:106] Iteration 43000, lr = 4.096e-06
I1216 13:31:39.973482 34688 solver.cpp:349] Iteration 44000, Testing net (#0)
I1216 13:31:41.964859 34688 solver.cpp:416]     Test net output #0: accuracy = 2.84755 (* 1 = 2.84755 loss)
I1216 13:31:41.964944 34688 solver.cpp:416]     Test net output #1: loss = 2.84755 (* 1 = 2.84755 loss)
I1216 13:31:41.975417 34688 solver.cpp:240] Iteration 44000, loss = 4.23902
I1216 13:31:41.975463 34688 solver.cpp:256]     Train net output #0: loss = 4.23902 (* 1 = 4.23902 loss)
I1216 13:31:41.975491 34688 sgd_solver.cpp:106] Iteration 44000, lr = 4.096e-06
I1216 13:31:52.354923 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_45000.caffemodel
I1216 13:31:52.358875 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_45000.solverstate
I1216 13:31:52.360867 34688 solver.cpp:349] Iteration 45000, Testing net (#0)
I1216 13:31:54.487155 34688 solver.cpp:416]     Test net output #0: accuracy = 2.83896 (* 1 = 2.83896 loss)
I1216 13:31:54.487236 34688 solver.cpp:416]     Test net output #1: loss = 2.83896 (* 1 = 2.83896 loss)
I1216 13:31:54.539669 34688 solver.cpp:240] Iteration 45000, loss = 2.5145
I1216 13:31:54.539785 34688 solver.cpp:256]     Train net output #0: loss = 2.5145 (* 1 = 2.5145 loss)
I1216 13:31:54.539814 34688 sgd_solver.cpp:106] Iteration 45000, lr = 4.096e-06
I1216 13:32:04.917544 34688 solver.cpp:349] Iteration 46000, Testing net (#0)
I1216 13:32:06.977051 34688 solver.cpp:416]     Test net output #0: accuracy = 2.84599 (* 1 = 2.84599 loss)
I1216 13:32:06.977136 34688 solver.cpp:416]     Test net output #1: loss = 2.84599 (* 1 = 2.84599 loss)
I1216 13:32:06.987457 34688 solver.cpp:240] Iteration 46000, loss = 2.31916
I1216 13:32:06.987504 34688 solver.cpp:256]     Train net output #0: loss = 2.31916 (* 1 = 2.31916 loss)
I1216 13:32:06.987530 34688 sgd_solver.cpp:106] Iteration 46000, lr = 4.096e-06
I1216 13:32:17.977262 34688 solver.cpp:349] Iteration 47000, Testing net (#0)
I1216 13:32:19.966670 34688 solver.cpp:416]     Test net output #0: accuracy = 2.8149 (* 1 = 2.8149 loss)
I1216 13:32:19.966753 34688 solver.cpp:416]     Test net output #1: loss = 2.8149 (* 1 = 2.8149 loss)
I1216 13:32:19.977138 34688 solver.cpp:240] Iteration 47000, loss = 2.3994
I1216 13:32:19.977185 34688 solver.cpp:256]     Train net output #0: loss = 2.3994 (* 1 = 2.3994 loss)
I1216 13:32:19.977212 34688 sgd_solver.cpp:106] Iteration 47000, lr = 4.096e-06
I1216 13:32:31.505172 34688 solver.cpp:349] Iteration 48000, Testing net (#0)
I1216 13:32:33.528969 34688 solver.cpp:416]     Test net output #0: accuracy = 2.82529 (* 1 = 2.82529 loss)
I1216 13:32:33.529054 34688 solver.cpp:416]     Test net output #1: loss = 2.82529 (* 1 = 2.82529 loss)
I1216 13:32:33.539516 34688 solver.cpp:240] Iteration 48000, loss = 3.43382
I1216 13:32:33.539564 34688 solver.cpp:256]     Train net output #0: loss = 3.43382 (* 1 = 3.43382 loss)
I1216 13:32:33.539592 34688 sgd_solver.cpp:106] Iteration 48000, lr = 4.096e-06
I1216 13:32:45.232326 34688 solver.cpp:349] Iteration 49000, Testing net (#0)
I1216 13:32:47.221828 34688 solver.cpp:416]     Test net output #0: accuracy = 2.80845 (* 1 = 2.80845 loss)
I1216 13:32:47.221904 34688 solver.cpp:416]     Test net output #1: loss = 2.80845 (* 1 = 2.80845 loss)
I1216 13:32:47.232357 34688 solver.cpp:240] Iteration 49000, loss = 4.21794
I1216 13:32:47.232404 34688 solver.cpp:256]     Train net output #0: loss = 4.21794 (* 1 = 4.21794 loss)
I1216 13:32:47.232431 34688 sgd_solver.cpp:106] Iteration 49000, lr = 4.096e-06
I1216 13:32:58.697865 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_50000.caffemodel
I1216 13:32:58.701752 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_50000.solverstate
I1216 13:32:58.703743 34688 solver.cpp:349] Iteration 50000, Testing net (#0)
I1216 13:33:00.721853 34688 solver.cpp:416]     Test net output #0: accuracy = 2.81845 (* 1 = 2.81845 loss)
I1216 13:33:00.721930 34688 solver.cpp:416]     Test net output #1: loss = 2.81845 (* 1 = 2.81845 loss)
I1216 13:33:00.772922 34688 solver.cpp:240] Iteration 50000, loss = 2.45819
I1216 13:33:00.773036 34688 solver.cpp:256]     Train net output #0: loss = 2.45819 (* 1 = 2.45819 loss)
I1216 13:33:00.773066 34688 sgd_solver.cpp:106] Iteration 50000, lr = 3.2768e-06
I1216 13:33:12.370249 34688 solver.cpp:349] Iteration 51000, Testing net (#0)
I1216 13:33:14.394336 34688 solver.cpp:416]     Test net output #0: accuracy = 2.79541 (* 1 = 2.79541 loss)
I1216 13:33:14.394429 34688 solver.cpp:416]     Test net output #1: loss = 2.79541 (* 1 = 2.79541 loss)
I1216 13:33:14.405612 34688 solver.cpp:240] Iteration 51000, loss = 2.28159
I1216 13:33:14.405674 34688 solver.cpp:256]     Train net output #0: loss = 2.28159 (* 1 = 2.28159 loss)
I1216 13:33:14.405711 34688 sgd_solver.cpp:106] Iteration 51000, lr = 3.2768e-06
I1216 13:33:25.931156 34688 solver.cpp:349] Iteration 52000, Testing net (#0)
I1216 13:33:27.921011 34688 solver.cpp:416]     Test net output #0: accuracy = 2.78318 (* 1 = 2.78318 loss)
I1216 13:33:27.921099 34688 solver.cpp:416]     Test net output #1: loss = 2.78318 (* 1 = 2.78318 loss)
I1216 13:33:27.931648 34688 solver.cpp:240] Iteration 52000, loss = 2.38517
I1216 13:33:27.931697 34688 solver.cpp:256]     Train net output #0: loss = 2.38517 (* 1 = 2.38517 loss)
I1216 13:33:27.931727 34688 sgd_solver.cpp:106] Iteration 52000, lr = 3.2768e-06
I1216 13:33:39.194224 34688 solver.cpp:349] Iteration 53000, Testing net (#0)
I1216 13:33:41.190361 34688 solver.cpp:416]     Test net output #0: accuracy = 2.80159 (* 1 = 2.80159 loss)
I1216 13:33:41.190440 34688 solver.cpp:416]     Test net output #1: loss = 2.80159 (* 1 = 2.80159 loss)
I1216 13:33:41.200866 34688 solver.cpp:240] Iteration 53000, loss = 3.38388
I1216 13:33:41.200913 34688 solver.cpp:256]     Train net output #0: loss = 3.38388 (* 1 = 3.38388 loss)
I1216 13:33:41.200939 34688 sgd_solver.cpp:106] Iteration 53000, lr = 3.2768e-06
I1216 13:33:52.412967 34688 solver.cpp:349] Iteration 54000, Testing net (#0)
I1216 13:33:54.435995 34688 solver.cpp:416]     Test net output #0: accuracy = 2.77125 (* 1 = 2.77125 loss)
I1216 13:33:54.436076 34688 solver.cpp:416]     Test net output #1: loss = 2.77125 (* 1 = 2.77125 loss)
I1216 13:33:54.446737 34688 solver.cpp:240] Iteration 54000, loss = 4.20134
I1216 13:33:54.446774 34688 solver.cpp:256]     Train net output #0: loss = 4.20134 (* 1 = 4.20134 loss)
I1216 13:33:54.446794 34688 sgd_solver.cpp:106] Iteration 54000, lr = 3.2768e-06
I1216 13:34:05.032570 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_55000.caffemodel
I1216 13:34:05.036487 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_55000.solverstate
I1216 13:34:05.038422 34688 solver.cpp:349] Iteration 55000, Testing net (#0)
I1216 13:34:07.010380 34688 solver.cpp:416]     Test net output #0: accuracy = 2.76544 (* 1 = 2.76544 loss)
I1216 13:34:07.010466 34688 solver.cpp:416]     Test net output #1: loss = 2.76544 (* 1 = 2.76544 loss)
I1216 13:34:07.063285 34688 solver.cpp:240] Iteration 55000, loss = 2.42273
I1216 13:34:07.063401 34688 solver.cpp:256]     Train net output #0: loss = 2.42273 (* 1 = 2.42273 loss)
I1216 13:34:07.063431 34688 sgd_solver.cpp:106] Iteration 55000, lr = 3.2768e-06
I1216 13:34:17.373003 34688 solver.cpp:349] Iteration 56000, Testing net (#0)
I1216 13:34:19.377686 34688 solver.cpp:416]     Test net output #0: accuracy = 2.77127 (* 1 = 2.77127 loss)
I1216 13:34:19.377777 34688 solver.cpp:416]     Test net output #1: loss = 2.77127 (* 1 = 2.77127 loss)
I1216 13:34:19.388387 34688 solver.cpp:240] Iteration 56000, loss = 2.25192
I1216 13:34:19.388434 34688 solver.cpp:256]     Train net output #0: loss = 2.25192 (* 1 = 2.25192 loss)
I1216 13:34:19.388463 34688 sgd_solver.cpp:106] Iteration 56000, lr = 3.2768e-06
I1216 13:34:29.822674 34688 solver.cpp:349] Iteration 57000, Testing net (#0)
I1216 13:34:31.857345 34688 solver.cpp:416]     Test net output #0: accuracy = 2.75948 (* 1 = 2.75948 loss)
I1216 13:34:31.857430 34688 solver.cpp:416]     Test net output #1: loss = 2.75948 (* 1 = 2.75948 loss)
I1216 13:34:31.868079 34688 solver.cpp:240] Iteration 57000, loss = 2.37026
I1216 13:34:31.868114 34688 solver.cpp:256]     Train net output #0: loss = 2.37026 (* 1 = 2.37026 loss)
I1216 13:34:31.868134 34688 sgd_solver.cpp:106] Iteration 57000, lr = 3.2768e-06
I1216 13:34:42.335194 34688 solver.cpp:349] Iteration 58000, Testing net (#0)
I1216 13:34:44.178216 34688 solver.cpp:416]     Test net output #0: accuracy = 2.75577 (* 1 = 2.75577 loss)
I1216 13:34:44.178308 34688 solver.cpp:416]     Test net output #1: loss = 2.75577 (* 1 = 2.75577 loss)
I1216 13:34:44.194531 34688 solver.cpp:240] Iteration 58000, loss = 3.34053
I1216 13:34:44.194594 34688 solver.cpp:256]     Train net output #0: loss = 3.34053 (* 1 = 3.34053 loss)
I1216 13:34:44.194628 34688 sgd_solver.cpp:106] Iteration 58000, lr = 3.2768e-06
I1216 13:34:54.693094 34688 solver.cpp:349] Iteration 59000, Testing net (#0)
I1216 13:34:56.534144 34688 solver.cpp:416]     Test net output #0: accuracy = 2.75192 (* 1 = 2.75192 loss)
I1216 13:34:56.534229 34688 solver.cpp:416]     Test net output #1: loss = 2.75192 (* 1 = 2.75192 loss)
I1216 13:34:56.549387 34688 solver.cpp:240] Iteration 59000, loss = 4.18484
I1216 13:34:56.549454 34688 solver.cpp:256]     Train net output #0: loss = 4.18484 (* 1 = 4.18484 loss)
I1216 13:34:56.549484 34688 sgd_solver.cpp:106] Iteration 59000, lr = 3.2768e-06
I1216 13:35:07.114850 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_60000.caffemodel
I1216 13:35:07.118815 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_60000.solverstate
I1216 13:35:07.120797 34688 solver.cpp:349] Iteration 60000, Testing net (#0)
I1216 13:35:09.101960 34688 solver.cpp:416]     Test net output #0: accuracy = 2.73305 (* 1 = 2.73305 loss)
I1216 13:35:09.102043 34688 solver.cpp:416]     Test net output #1: loss = 2.73305 (* 1 = 2.73305 loss)
I1216 13:35:09.154850 34688 solver.cpp:240] Iteration 60000, loss = 2.38714
I1216 13:35:09.154964 34688 solver.cpp:256]     Train net output #0: loss = 2.38714 (* 1 = 2.38714 loss)
I1216 13:35:09.154994 34688 sgd_solver.cpp:106] Iteration 60000, lr = 2.62144e-06
I1216 13:35:19.528497 34688 solver.cpp:349] Iteration 61000, Testing net (#0)
I1216 13:35:21.453784 34688 solver.cpp:416]     Test net output #0: accuracy = 2.74416 (* 1 = 2.74416 loss)
I1216 13:35:21.453868 34688 solver.cpp:416]     Test net output #1: loss = 2.74416 (* 1 = 2.74416 loss)
I1216 13:35:21.464421 34688 solver.cpp:240] Iteration 61000, loss = 2.22034
I1216 13:35:21.464469 34688 solver.cpp:256]     Train net output #0: loss = 2.22035 (* 1 = 2.22035 loss)
I1216 13:35:21.464498 34688 sgd_solver.cpp:106] Iteration 61000, lr = 2.62144e-06
I1216 13:35:32.037978 34688 solver.cpp:349] Iteration 62000, Testing net (#0)
I1216 13:35:33.888108 34688 solver.cpp:416]     Test net output #0: accuracy = 2.7261 (* 1 = 2.7261 loss)
I1216 13:35:33.888195 34688 solver.cpp:416]     Test net output #1: loss = 2.7261 (* 1 = 2.7261 loss)
I1216 13:35:33.903611 34688 solver.cpp:240] Iteration 62000, loss = 2.3573
I1216 13:35:33.903678 34688 solver.cpp:256]     Train net output #0: loss = 2.3573 (* 1 = 2.3573 loss)
I1216 13:35:33.903705 34688 sgd_solver.cpp:106] Iteration 62000, lr = 2.62144e-06
I1216 13:35:45.314029 34688 solver.cpp:349] Iteration 63000, Testing net (#0)
I1216 13:35:47.160727 34688 solver.cpp:416]     Test net output #0: accuracy = 2.74054 (* 1 = 2.74054 loss)
I1216 13:35:47.160815 34688 solver.cpp:416]     Test net output #1: loss = 2.74054 (* 1 = 2.74054 loss)
I1216 13:35:47.176998 34688 solver.cpp:240] Iteration 63000, loss = 3.30098
I1216 13:35:47.177059 34688 solver.cpp:256]     Train net output #0: loss = 3.30098 (* 1 = 3.30098 loss)
I1216 13:35:47.177088 34688 sgd_solver.cpp:106] Iteration 63000, lr = 2.62144e-06
I1216 13:35:57.843816 34688 solver.cpp:349] Iteration 64000, Testing net (#0)
I1216 13:35:59.683471 34688 solver.cpp:416]     Test net output #0: accuracy = 2.72831 (* 1 = 2.72831 loss)
I1216 13:35:59.683560 34688 solver.cpp:416]     Test net output #1: loss = 2.72831 (* 1 = 2.72831 loss)
I1216 13:35:59.698683 34688 solver.cpp:240] Iteration 64000, loss = 4.16921
I1216 13:35:59.698755 34688 solver.cpp:256]     Train net output #0: loss = 4.16921 (* 1 = 4.16921 loss)
I1216 13:35:59.698782 34688 sgd_solver.cpp:106] Iteration 64000, lr = 2.62144e-06
I1216 13:36:10.257355 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_65000.caffemodel
I1216 13:36:10.261237 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_65000.solverstate
I1216 13:36:10.263245 34688 solver.cpp:349] Iteration 65000, Testing net (#0)
I1216 13:36:12.251566 34688 solver.cpp:416]     Test net output #0: accuracy = 2.70227 (* 1 = 2.70227 loss)
I1216 13:36:12.251647 34688 solver.cpp:416]     Test net output #1: loss = 2.70227 (* 1 = 2.70227 loss)
I1216 13:36:12.292453 34688 solver.cpp:240] Iteration 65000, loss = 2.36359
I1216 13:36:12.292554 34688 solver.cpp:256]     Train net output #0: loss = 2.36359 (* 1 = 2.36359 loss)
I1216 13:36:12.292585 34688 sgd_solver.cpp:106] Iteration 65000, lr = 2.62144e-06
I1216 13:36:22.727373 34688 solver.cpp:349] Iteration 66000, Testing net (#0)
I1216 13:36:24.569420 34688 solver.cpp:416]     Test net output #0: accuracy = 2.722 (* 1 = 2.722 loss)
I1216 13:36:24.569507 34688 solver.cpp:416]     Test net output #1: loss = 2.722 (* 1 = 2.722 loss)
I1216 13:36:24.581933 34688 solver.cpp:240] Iteration 66000, loss = 2.19542
I1216 13:36:24.582005 34688 solver.cpp:256]     Train net output #0: loss = 2.19542 (* 1 = 2.19542 loss)
I1216 13:36:24.582032 34688 sgd_solver.cpp:106] Iteration 66000, lr = 2.62144e-06
I1216 13:36:35.088775 34688 solver.cpp:349] Iteration 67000, Testing net (#0)
I1216 13:36:36.899137 34688 solver.cpp:416]     Test net output #0: accuracy = 2.6994 (* 1 = 2.6994 loss)
I1216 13:36:36.899215 34688 solver.cpp:416]     Test net output #1: loss = 2.6994 (* 1 = 2.6994 loss)
I1216 13:36:36.910012 34688 solver.cpp:240] Iteration 67000, loss = 2.34383
I1216 13:36:36.910061 34688 solver.cpp:256]     Train net output #0: loss = 2.34383 (* 1 = 2.34383 loss)
I1216 13:36:36.910089 34688 sgd_solver.cpp:106] Iteration 67000, lr = 2.62144e-06
I1216 13:36:47.415097 34688 solver.cpp:349] Iteration 68000, Testing net (#0)
I1216 13:36:49.269546 34688 solver.cpp:416]     Test net output #0: accuracy = 2.70036 (* 1 = 2.70036 loss)
I1216 13:36:49.269631 34688 solver.cpp:416]     Test net output #1: loss = 2.70036 (* 1 = 2.70036 loss)
I1216 13:36:49.285995 34688 solver.cpp:240] Iteration 68000, loss = 3.263
I1216 13:36:49.286058 34688 solver.cpp:256]     Train net output #0: loss = 3.263 (* 1 = 3.263 loss)
I1216 13:36:49.286087 34688 sgd_solver.cpp:106] Iteration 68000, lr = 2.62144e-06
I1216 13:36:59.763433 34688 solver.cpp:349] Iteration 69000, Testing net (#0)
I1216 13:37:01.645900 34688 solver.cpp:416]     Test net output #0: accuracy = 2.69042 (* 1 = 2.69042 loss)
I1216 13:37:01.645992 34688 solver.cpp:416]     Test net output #1: loss = 2.69042 (* 1 = 2.69042 loss)
I1216 13:37:01.656831 34688 solver.cpp:240] Iteration 69000, loss = 4.15362
I1216 13:37:01.656879 34688 solver.cpp:256]     Train net output #0: loss = 4.15362 (* 1 = 4.15362 loss)
I1216 13:37:01.656909 34688 sgd_solver.cpp:106] Iteration 69000, lr = 2.62144e-06
I1216 13:37:12.258041 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_70000.caffemodel
I1216 13:37:12.261950 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_70000.solverstate
I1216 13:37:12.263936 34688 solver.cpp:349] Iteration 70000, Testing net (#0)
I1216 13:37:14.090059 34688 solver.cpp:416]     Test net output #0: accuracy = 2.68973 (* 1 = 2.68973 loss)
I1216 13:37:14.090145 34688 solver.cpp:416]     Test net output #1: loss = 2.68973 (* 1 = 2.68973 loss)
I1216 13:37:14.137804 34688 solver.cpp:240] Iteration 70000, loss = 2.33823
I1216 13:37:14.137912 34688 solver.cpp:256]     Train net output #0: loss = 2.33823 (* 1 = 2.33823 loss)
I1216 13:37:14.137943 34688 sgd_solver.cpp:106] Iteration 70000, lr = 2.09715e-06
I1216 13:37:25.160769 34688 solver.cpp:349] Iteration 71000, Testing net (#0)
I1216 13:37:26.995404 34688 solver.cpp:416]     Test net output #0: accuracy = 2.68651 (* 1 = 2.68651 loss)
I1216 13:37:26.995487 34688 solver.cpp:416]     Test net output #1: loss = 2.68651 (* 1 = 2.68651 loss)
I1216 13:37:27.007830 34688 solver.cpp:240] Iteration 71000, loss = 2.17231
I1216 13:37:27.007910 34688 solver.cpp:256]     Train net output #0: loss = 2.17231 (* 1 = 2.17231 loss)
I1216 13:37:27.007939 34688 sgd_solver.cpp:106] Iteration 71000, lr = 2.09715e-06
I1216 13:37:37.608950 34688 solver.cpp:349] Iteration 72000, Testing net (#0)
I1216 13:37:39.482786 34688 solver.cpp:416]     Test net output #0: accuracy = 2.68531 (* 1 = 2.68531 loss)
I1216 13:37:39.482877 34688 solver.cpp:416]     Test net output #1: loss = 2.68531 (* 1 = 2.68531 loss)
I1216 13:37:39.494299 34688 solver.cpp:240] Iteration 72000, loss = 2.33422
I1216 13:37:39.494349 34688 solver.cpp:256]     Train net output #0: loss = 2.33422 (* 1 = 2.33422 loss)
I1216 13:37:39.494374 34688 sgd_solver.cpp:106] Iteration 72000, lr = 2.09715e-06
I1216 13:37:49.952810 34688 solver.cpp:349] Iteration 73000, Testing net (#0)
I1216 13:37:51.823895 34688 solver.cpp:416]     Test net output #0: accuracy = 2.66594 (* 1 = 2.66594 loss)
I1216 13:37:51.823981 34688 solver.cpp:416]     Test net output #1: loss = 2.66594 (* 1 = 2.66594 loss)
I1216 13:37:51.835026 34688 solver.cpp:240] Iteration 73000, loss = 3.2247
I1216 13:37:51.835073 34688 solver.cpp:256]     Train net output #0: loss = 3.2247 (* 1 = 3.2247 loss)
I1216 13:37:51.835099 34688 sgd_solver.cpp:106] Iteration 73000, lr = 2.09715e-06
I1216 13:38:02.359493 34688 solver.cpp:349] Iteration 74000, Testing net (#0)
I1216 13:38:04.230669 34688 solver.cpp:416]     Test net output #0: accuracy = 2.67868 (* 1 = 2.67868 loss)
I1216 13:38:04.230756 34688 solver.cpp:416]     Test net output #1: loss = 2.67868 (* 1 = 2.67868 loss)
I1216 13:38:04.241681 34688 solver.cpp:240] Iteration 74000, loss = 4.13938
I1216 13:38:04.241727 34688 solver.cpp:256]     Train net output #0: loss = 4.13938 (* 1 = 4.13938 loss)
I1216 13:38:04.241755 34688 sgd_solver.cpp:106] Iteration 74000, lr = 2.09715e-06
I1216 13:38:14.663061 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_75000.caffemodel
I1216 13:38:14.667387 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_75000.solverstate
I1216 13:38:14.669385 34688 solver.cpp:349] Iteration 75000, Testing net (#0)
I1216 13:38:16.545855 34688 solver.cpp:416]     Test net output #0: accuracy = 2.66641 (* 1 = 2.66641 loss)
I1216 13:38:16.545943 34688 solver.cpp:416]     Test net output #1: loss = 2.66641 (* 1 = 2.66641 loss)
I1216 13:38:16.599244 34688 solver.cpp:240] Iteration 75000, loss = 2.31992
I1216 13:38:16.599360 34688 solver.cpp:256]     Train net output #0: loss = 2.31992 (* 1 = 2.31992 loss)
I1216 13:38:16.599390 34688 sgd_solver.cpp:106] Iteration 75000, lr = 2.09715e-06
I1216 13:38:27.221089 34688 solver.cpp:349] Iteration 76000, Testing net (#0)
I1216 13:38:29.030091 34688 solver.cpp:416]     Test net output #0: accuracy = 2.67607 (* 1 = 2.67607 loss)
I1216 13:38:29.030174 34688 solver.cpp:416]     Test net output #1: loss = 2.67607 (* 1 = 2.67607 loss)
I1216 13:38:29.032516 34688 solver.cpp:240] Iteration 76000, loss = 2.15353
I1216 13:38:29.032565 34688 solver.cpp:256]     Train net output #0: loss = 2.15353 (* 1 = 2.15353 loss)
I1216 13:38:29.032593 34688 sgd_solver.cpp:106] Iteration 76000, lr = 2.09715e-06
I1216 13:38:39.932979 34688 solver.cpp:349] Iteration 77000, Testing net (#0)
I1216 13:38:41.808924 34688 solver.cpp:416]     Test net output #0: accuracy = 2.66363 (* 1 = 2.66363 loss)
I1216 13:38:41.809012 34688 solver.cpp:416]     Test net output #1: loss = 2.66363 (* 1 = 2.66363 loss)
I1216 13:38:41.819923 34688 solver.cpp:240] Iteration 77000, loss = 2.32564
I1216 13:38:41.819972 34688 solver.cpp:256]     Train net output #0: loss = 2.32564 (* 1 = 2.32564 loss)
I1216 13:38:41.820000 34688 sgd_solver.cpp:106] Iteration 77000, lr = 2.09715e-06
I1216 13:38:53.123895 34688 solver.cpp:349] Iteration 78000, Testing net (#0)
I1216 13:38:54.978626 34688 solver.cpp:416]     Test net output #0: accuracy = 2.64427 (* 1 = 2.64427 loss)
I1216 13:38:54.978716 34688 solver.cpp:416]     Test net output #1: loss = 2.64427 (* 1 = 2.64427 loss)
I1216 13:38:54.995242 34688 solver.cpp:240] Iteration 78000, loss = 3.19138
I1216 13:38:54.995304 34688 solver.cpp:256]     Train net output #0: loss = 3.19138 (* 1 = 3.19138 loss)
I1216 13:38:54.995332 34688 sgd_solver.cpp:106] Iteration 78000, lr = 2.09715e-06
I1216 13:39:06.177366 34688 solver.cpp:349] Iteration 79000, Testing net (#0)
I1216 13:39:08.053633 34688 solver.cpp:416]     Test net output #0: accuracy = 2.66075 (* 1 = 2.66075 loss)
I1216 13:39:08.053717 34688 solver.cpp:416]     Test net output #1: loss = 2.66075 (* 1 = 2.66075 loss)
I1216 13:39:08.064636 34688 solver.cpp:240] Iteration 79000, loss = 4.12549
I1216 13:39:08.064684 34688 solver.cpp:256]     Train net output #0: loss = 4.12549 (* 1 = 4.12549 loss)
I1216 13:39:08.064712 34688 sgd_solver.cpp:106] Iteration 79000, lr = 2.09715e-06
I1216 13:39:18.805557 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_80000.caffemodel
I1216 13:39:18.809404 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_80000.solverstate
I1216 13:39:18.811430 34688 solver.cpp:349] Iteration 80000, Testing net (#0)
I1216 13:39:20.683166 34688 solver.cpp:416]     Test net output #0: accuracy = 2.64164 (* 1 = 2.64164 loss)
I1216 13:39:20.683248 34688 solver.cpp:416]     Test net output #1: loss = 2.64164 (* 1 = 2.64164 loss)
I1216 13:39:20.736351 34688 solver.cpp:240] Iteration 80000, loss = 2.30114
I1216 13:39:20.736464 34688 solver.cpp:256]     Train net output #0: loss = 2.30114 (* 1 = 2.30114 loss)
I1216 13:39:20.736492 34688 sgd_solver.cpp:106] Iteration 80000, lr = 1.67772e-06
I1216 13:39:31.145264 34688 solver.cpp:349] Iteration 81000, Testing net (#0)
I1216 13:39:33.011611 34688 solver.cpp:416]     Test net output #0: accuracy = 2.64807 (* 1 = 2.64807 loss)
I1216 13:39:33.011695 34688 solver.cpp:416]     Test net output #1: loss = 2.64807 (* 1 = 2.64807 loss)
I1216 13:39:33.023345 34688 solver.cpp:240] Iteration 81000, loss = 2.13541
I1216 13:39:33.023396 34688 solver.cpp:256]     Train net output #0: loss = 2.13541 (* 1 = 2.13541 loss)
I1216 13:39:33.023423 34688 sgd_solver.cpp:106] Iteration 81000, lr = 1.67772e-06
I1216 13:39:43.441953 34688 solver.cpp:349] Iteration 82000, Testing net (#0)
I1216 13:39:45.315066 34688 solver.cpp:416]     Test net output #0: accuracy = 2.63855 (* 1 = 2.63855 loss)
I1216 13:39:45.315150 34688 solver.cpp:416]     Test net output #1: loss = 2.63855 (* 1 = 2.63855 loss)
I1216 13:39:45.326019 34688 solver.cpp:240] Iteration 82000, loss = 2.31956
I1216 13:39:45.326064 34688 solver.cpp:256]     Train net output #0: loss = 2.31957 (* 1 = 2.31957 loss)
I1216 13:39:45.326091 34688 sgd_solver.cpp:106] Iteration 82000, lr = 1.67772e-06
I1216 13:39:55.826625 34688 solver.cpp:349] Iteration 83000, Testing net (#0)
I1216 13:39:57.693950 34688 solver.cpp:416]     Test net output #0: accuracy = 2.64017 (* 1 = 2.64017 loss)
I1216 13:39:57.694034 34688 solver.cpp:416]     Test net output #1: loss = 2.64017 (* 1 = 2.64017 loss)
I1216 13:39:57.704957 34688 solver.cpp:240] Iteration 83000, loss = 3.1615
I1216 13:39:57.705005 34688 solver.cpp:256]     Train net output #0: loss = 3.1615 (* 1 = 3.1615 loss)
I1216 13:39:57.705032 34688 sgd_solver.cpp:106] Iteration 83000, lr = 1.67772e-06
I1216 13:40:08.187661 34688 solver.cpp:349] Iteration 84000, Testing net (#0)
I1216 13:40:10.072741 34688 solver.cpp:416]     Test net output #0: accuracy = 2.63453 (* 1 = 2.63453 loss)
I1216 13:40:10.072830 34688 solver.cpp:416]     Test net output #1: loss = 2.63453 (* 1 = 2.63453 loss)
I1216 13:40:10.084625 34688 solver.cpp:240] Iteration 84000, loss = 4.11255
I1216 13:40:10.084676 34688 solver.cpp:256]     Train net output #0: loss = 4.11256 (* 1 = 4.11256 loss)
I1216 13:40:10.084703 34688 sgd_solver.cpp:106] Iteration 84000, lr = 1.67772e-06
I1216 13:40:20.648216 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_85000.caffemodel
I1216 13:40:20.652108 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_85000.solverstate
I1216 13:40:20.654038 34688 solver.cpp:349] Iteration 85000, Testing net (#0)
I1216 13:40:22.470722 34688 solver.cpp:416]     Test net output #0: accuracy = 2.63263 (* 1 = 2.63263 loss)
I1216 13:40:22.470804 34688 solver.cpp:416]     Test net output #1: loss = 2.63263 (* 1 = 2.63263 loss)
I1216 13:40:22.521349 34688 solver.cpp:240] Iteration 85000, loss = 2.28991
I1216 13:40:22.521462 34688 solver.cpp:256]     Train net output #0: loss = 2.28991 (* 1 = 2.28991 loss)
I1216 13:40:22.521492 34688 sgd_solver.cpp:106] Iteration 85000, lr = 1.67772e-06
I1216 13:40:33.979657 34688 solver.cpp:349] Iteration 86000, Testing net (#0)
I1216 13:40:35.853117 34688 solver.cpp:416]     Test net output #0: accuracy = 2.62166 (* 1 = 2.62166 loss)
I1216 13:40:35.853205 34688 solver.cpp:416]     Test net output #1: loss = 2.62166 (* 1 = 2.62166 loss)
I1216 13:40:35.863819 34688 solver.cpp:240] Iteration 86000, loss = 2.12063
I1216 13:40:35.863867 34688 solver.cpp:256]     Train net output #0: loss = 2.12063 (* 1 = 2.12063 loss)
I1216 13:40:35.863893 34688 sgd_solver.cpp:106] Iteration 86000, lr = 1.67772e-06
I1216 13:40:46.985882 34688 solver.cpp:349] Iteration 87000, Testing net (#0)
I1216 13:40:48.862355 34688 solver.cpp:416]     Test net output #0: accuracy = 2.63241 (* 1 = 2.63241 loss)
I1216 13:40:48.862440 34688 solver.cpp:416]     Test net output #1: loss = 2.63241 (* 1 = 2.63241 loss)
I1216 13:40:48.873266 34688 solver.cpp:240] Iteration 87000, loss = 2.3152
I1216 13:40:48.873313 34688 solver.cpp:256]     Train net output #0: loss = 2.3152 (* 1 = 2.3152 loss)
I1216 13:40:48.873340 34688 sgd_solver.cpp:106] Iteration 87000, lr = 1.67772e-06
I1216 13:40:59.626283 34688 solver.cpp:349] Iteration 88000, Testing net (#0)
I1216 13:41:01.584458 34688 solver.cpp:416]     Test net output #0: accuracy = 2.61764 (* 1 = 2.61764 loss)
I1216 13:41:01.584543 34688 solver.cpp:416]     Test net output #1: loss = 2.61764 (* 1 = 2.61764 loss)
I1216 13:41:01.595435 34688 solver.cpp:240] Iteration 88000, loss = 3.13539
I1216 13:41:01.595482 34688 solver.cpp:256]     Train net output #0: loss = 3.13539 (* 1 = 3.13539 loss)
I1216 13:41:01.595512 34688 sgd_solver.cpp:106] Iteration 88000, lr = 1.67772e-06
I1216 13:41:12.639873 34688 solver.cpp:349] Iteration 89000, Testing net (#0)
I1216 13:41:14.513031 34688 solver.cpp:416]     Test net output #0: accuracy = 2.62896 (* 1 = 2.62896 loss)
I1216 13:41:14.513114 34688 solver.cpp:416]     Test net output #1: loss = 2.62896 (* 1 = 2.62896 loss)
I1216 13:41:14.523898 34688 solver.cpp:240] Iteration 89000, loss = 4.11961
I1216 13:41:14.523946 34688 solver.cpp:256]     Train net output #0: loss = 4.11961 (* 1 = 4.11961 loss)
I1216 13:41:14.523972 34688 sgd_solver.cpp:106] Iteration 89000, lr = 1.67772e-06
I1216 13:41:25.257148 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_90000.caffemodel
I1216 13:41:25.261210 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_90000.solverstate
I1216 13:41:25.263164 34688 solver.cpp:349] Iteration 90000, Testing net (#0)
I1216 13:41:27.171217 34688 solver.cpp:416]     Test net output #0: accuracy = 2.62086 (* 1 = 2.62086 loss)
I1216 13:41:27.171298 34688 solver.cpp:416]     Test net output #1: loss = 2.62086 (* 1 = 2.62086 loss)
I1216 13:41:27.224433 34688 solver.cpp:240] Iteration 90000, loss = 2.27441
I1216 13:41:27.224550 34688 solver.cpp:256]     Train net output #0: loss = 2.27441 (* 1 = 2.27441 loss)
I1216 13:41:27.224578 34688 sgd_solver.cpp:106] Iteration 90000, lr = 1.34218e-06
I1216 13:41:37.802713 34688 solver.cpp:349] Iteration 91000, Testing net (#0)
I1216 13:41:39.661854 34688 solver.cpp:416]     Test net output #0: accuracy = 2.60467 (* 1 = 2.60467 loss)
I1216 13:41:39.661937 34688 solver.cpp:416]     Test net output #1: loss = 2.60467 (* 1 = 2.60467 loss)
I1216 13:41:39.676002 34688 solver.cpp:240] Iteration 91000, loss = 2.10694
I1216 13:41:39.676057 34688 solver.cpp:256]     Train net output #0: loss = 2.10694 (* 1 = 2.10694 loss)
I1216 13:41:39.676085 34688 sgd_solver.cpp:106] Iteration 91000, lr = 1.34218e-06
I1216 13:41:50.064913 34688 solver.cpp:349] Iteration 92000, Testing net (#0)
I1216 13:41:51.906909 34688 solver.cpp:416]     Test net output #0: accuracy = 2.62022 (* 1 = 2.62022 loss)
I1216 13:41:51.906994 34688 solver.cpp:416]     Test net output #1: loss = 2.62022 (* 1 = 2.62022 loss)
I1216 13:41:51.918892 34688 solver.cpp:240] Iteration 92000, loss = 2.31089
I1216 13:41:51.918965 34688 solver.cpp:256]     Train net output #0: loss = 2.31089 (* 1 = 2.31089 loss)
I1216 13:41:51.918993 34688 sgd_solver.cpp:106] Iteration 92000, lr = 1.34218e-06
I1216 13:42:02.559936 34688 solver.cpp:349] Iteration 93000, Testing net (#0)
I1216 13:42:04.374332 34688 solver.cpp:416]     Test net output #0: accuracy = 2.60068 (* 1 = 2.60068 loss)
I1216 13:42:04.374413 34688 solver.cpp:416]     Test net output #1: loss = 2.60068 (* 1 = 2.60068 loss)
I1216 13:42:04.376852 34688 solver.cpp:240] Iteration 93000, loss = 3.11318
I1216 13:42:04.376912 34688 solver.cpp:256]     Train net output #0: loss = 3.11317 (* 1 = 3.11317 loss)
I1216 13:42:04.376940 34688 sgd_solver.cpp:106] Iteration 93000, lr = 1.34218e-06
I1216 13:42:14.825307 34688 solver.cpp:349] Iteration 94000, Testing net (#0)
I1216 13:42:16.768636 34688 solver.cpp:416]     Test net output #0: accuracy = 2.60846 (* 1 = 2.60846 loss)
I1216 13:42:16.768720 34688 solver.cpp:416]     Test net output #1: loss = 2.60846 (* 1 = 2.60846 loss)
I1216 13:42:16.779639 34688 solver.cpp:240] Iteration 94000, loss = 4.12294
I1216 13:42:16.779685 34688 solver.cpp:256]     Train net output #0: loss = 4.12294 (* 1 = 4.12294 loss)
I1216 13:42:16.779712 34688 sgd_solver.cpp:106] Iteration 94000, lr = 1.34218e-06
I1216 13:42:27.107924 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_95000.caffemodel
I1216 13:42:27.111769 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_95000.solverstate
I1216 13:42:27.113698 34688 solver.cpp:349] Iteration 95000, Testing net (#0)
I1216 13:42:28.981266 34688 solver.cpp:416]     Test net output #0: accuracy = 2.59695 (* 1 = 2.59695 loss)
I1216 13:42:28.981350 34688 solver.cpp:416]     Test net output #1: loss = 2.59695 (* 1 = 2.59695 loss)
I1216 13:42:29.034747 34688 solver.cpp:240] Iteration 95000, loss = 2.26216
I1216 13:42:29.034865 34688 solver.cpp:256]     Train net output #0: loss = 2.26216 (* 1 = 2.26216 loss)
I1216 13:42:29.034896 34688 sgd_solver.cpp:106] Iteration 95000, lr = 1.34218e-06
I1216 13:42:39.729426 34688 solver.cpp:349] Iteration 96000, Testing net (#0)
I1216 13:42:41.641741 34688 solver.cpp:416]     Test net output #0: accuracy = 2.60468 (* 1 = 2.60468 loss)
I1216 13:42:41.641829 34688 solver.cpp:416]     Test net output #1: loss = 2.60468 (* 1 = 2.60468 loss)
I1216 13:42:41.644299 34688 solver.cpp:240] Iteration 96000, loss = 2.09612
I1216 13:42:41.644353 34688 solver.cpp:256]     Train net output #0: loss = 2.09612 (* 1 = 2.09612 loss)
I1216 13:42:41.644384 34688 sgd_solver.cpp:106] Iteration 96000, lr = 1.34218e-06
I1216 13:42:52.552738 34688 solver.cpp:349] Iteration 97000, Testing net (#0)
I1216 13:42:54.404784 34688 solver.cpp:416]     Test net output #0: accuracy = 2.60136 (* 1 = 2.60136 loss)
I1216 13:42:54.404871 34688 solver.cpp:416]     Test net output #1: loss = 2.60136 (* 1 = 2.60136 loss)
I1216 13:42:54.416362 34688 solver.cpp:240] Iteration 97000, loss = 2.30583
I1216 13:42:54.416445 34688 solver.cpp:256]     Train net output #0: loss = 2.30583 (* 1 = 2.30583 loss)
I1216 13:42:54.416473 34688 sgd_solver.cpp:106] Iteration 97000, lr = 1.34218e-06
I1216 13:43:05.106189 34688 solver.cpp:349] Iteration 98000, Testing net (#0)
I1216 13:43:06.957953 34688 solver.cpp:416]     Test net output #0: accuracy = 2.59379 (* 1 = 2.59379 loss)
I1216 13:43:06.958041 34688 solver.cpp:416]     Test net output #1: loss = 2.59379 (* 1 = 2.59379 loss)
I1216 13:43:06.974601 34688 solver.cpp:240] Iteration 98000, loss = 3.09476
I1216 13:43:06.974663 34688 solver.cpp:256]     Train net output #0: loss = 3.09476 (* 1 = 3.09476 loss)
I1216 13:43:06.974692 34688 sgd_solver.cpp:106] Iteration 98000, lr = 1.34218e-06
I1216 13:43:17.625862 34688 solver.cpp:349] Iteration 99000, Testing net (#0)
I1216 13:43:19.430857 34688 solver.cpp:416]     Test net output #0: accuracy = 2.59212 (* 1 = 2.59212 loss)
I1216 13:43:19.430941 34688 solver.cpp:416]     Test net output #1: loss = 2.59212 (* 1 = 2.59212 loss)
I1216 13:43:19.433300 34688 solver.cpp:240] Iteration 99000, loss = 4.12297
I1216 13:43:19.433352 34688 solver.cpp:256]     Train net output #0: loss = 4.12298 (* 1 = 4.12298 loss)
I1216 13:43:19.433380 34688 sgd_solver.cpp:106] Iteration 99000, lr = 1.34218e-06
I1216 13:43:29.929736 34688 solver.cpp:466] Snapshotting to binary proto file ../model/_iter_100000.caffemodel
I1216 13:43:29.933620 34688 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../model/_iter_100000.solverstate
I1216 13:43:29.987977 34688 solver.cpp:329] Iteration 100000, loss = 2.24855
I1216 13:43:29.988092 34688 solver.cpp:349] Iteration 100000, Testing net (#0)
I1216 13:43:31.848682 34688 solver.cpp:416]     Test net output #0: accuracy = 2.59173 (* 1 = 2.59173 loss)
I1216 13:43:31.848767 34688 solver.cpp:416]     Test net output #1: loss = 2.59173 (* 1 = 2.59173 loss)
I1216 13:43:31.848788 34688 solver.cpp:334] Optimization Done.
I1216 13:43:31.848803 34688 caffe.cpp:254] Optimization Done.
